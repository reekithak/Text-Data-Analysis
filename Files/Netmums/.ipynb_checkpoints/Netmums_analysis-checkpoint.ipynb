{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T20:16:00.810418Z",
     "start_time": "2020-09-25T20:14:37.140341Z"
    }
   },
   "source": [
    "# Netmums - Forum Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T21:01:42.067603Z",
     "start_time": "2020-09-25T21:01:42.035685Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Akhil\n",
      "[nltk_data]     Sanker\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Akhil\n",
      "[nltk_data]     Sanker\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Akhil\n",
      "[nltk_data]     Sanker\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Akhil Sanker\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "#stopwords\n",
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "\n",
    "#stemming\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk \n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "#lemmatizing\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#POS\n",
    "def word_pos_tagger(text):\n",
    "    pos_tagged_text = nltk.pos_tag(text)\n",
    "    return pos_tagged_text\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "#chunking\n",
    "import spacy\n",
    "import en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T21:02:34.677470Z",
     "start_time": "2020-09-25T21:02:33.193317Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python3\\lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T20:16:00.825410Z",
     "start_time": "2020-09-25T20:16:00.813410Z"
    }
   },
   "outputs": [],
   "source": [
    "def word_lemmatizer(text):\n",
    "    lem_text = [WordNetLemmatizer().lemmatize(i) for i in text]\n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T20:01:55.802743Z",
     "start_time": "2020-09-25T20:01:55.774306Z"
    }
   },
   "outputs": [],
   "source": [
    "chat_slang = pd.read_excel(\"Chat_Slang_Dictionary.xlsx\")\n",
    "slang_dict = dict(zip(chat_slang['Chat Term'],chat_slang['Translated Term'])) #create a dictionary for swapping later as part of \n",
    "#preprocessing\n",
    "slang = list(slang_dict.keys())\n",
    "slang_dict[\"cp\"] = \"child porn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T20:02:53.627598Z",
     "start_time": "2020-09-25T20:02:53.254911Z"
    }
   },
   "outputs": [],
   "source": [
    "nm = pd.read_excel(\"Netmums.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T20:03:27.083180Z",
     "start_time": "2020-09-25T20:03:27.073206Z"
    }
   },
   "outputs": [],
   "source": [
    "nm.drop('Name',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T20:04:07.661321Z",
     "start_time": "2020-09-25T20:04:07.642371Z"
    }
   },
   "outputs": [],
   "source": [
    "def replace_slang(string):\n",
    "    global slang , slang_dict\n",
    "    for s in slang:\n",
    "        if s in string.lower().split():\n",
    "            string = string.replace(s,slang_dict[s])\n",
    "        else:\n",
    "            pass\n",
    "    return string \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T20:04:13.582419Z",
     "start_time": "2020-09-25T20:04:13.565462Z"
    }
   },
   "outputs": [],
   "source": [
    "si = ['\\n','.',',','\"',';',':','\\t']\n",
    "def clean_base(string):\n",
    "    for s in si:\n",
    "        \n",
    "        if s in string.lower():\n",
    "\n",
    "            string = string.replace(s,\" \")\n",
    "        else:\n",
    "            pass\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T20:05:17.677789Z",
     "start_time": "2020-09-25T20:05:17.655848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My daughter is 12 and will be 13 very soon. Sh...</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not the nicest start to the summer holidays wh...</td>\n",
       "      <td>23</td>\n",
       "      <td>9003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HmmHmmPost edited by Michelino on 05-08-2020 a...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I hope i'm posting this in right place and hop...</td>\n",
       "      <td>12</td>\n",
       "      <td>4114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>During the last week of school in my daughters...</td>\n",
       "      <td>5</td>\n",
       "      <td>3179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Replies  Views\n",
       "0  My daughter is 12 and will be 13 very soon. Sh...        2     55\n",
       "1  Not the nicest start to the summer holidays wh...       23   9003\n",
       "2  HmmHmmPost edited by Michelino on 05-08-2020 a...        0     13\n",
       "3  I hope i'm posting this in right place and hop...       12   4114\n",
       "4  During the last week of school in my daughters...        5   3179"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T20:07:35.660942Z",
     "start_time": "2020-09-25T20:07:33.289878Z"
    }
   },
   "outputs": [],
   "source": [
    "Content = []\n",
    "for i in range(nm.shape[0]):\n",
    "    new_str = clean_base(nm['Content'][i])\n",
    "    new_str = replace_slang(new_str)\n",
    "    Content.append(new_str)\n",
    "try:\n",
    "    nm['text'] = Content\n",
    "    nm.drop('Content',axis=1,inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T20:10:11.330663Z",
     "start_time": "2020-09-25T20:10:10.510166Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def  clean_text(df, text_field, new_text_field_name):\n",
    "    df[new_text_field_name] = df[text_field].str.lower()\n",
    "    df[new_text_field_name] = df[new_text_field_name].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    # remove numbers\n",
    "    df[new_text_field_name] = df[new_text_field_name].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
    "    \n",
    "    return df\n",
    "data_clean = clean_text(nm, 'text', 'text_clean')\n",
    "data_clean.head()\n",
    "nm=data_clean\n",
    "try:\n",
    "    nm.drop(\"text\",axis=1,inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T20:10:40.389474Z",
     "start_time": "2020-09-25T20:10:40.349580Z"
    }
   },
   "source": [
    "**Stop Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T20:12:05.973356Z",
     "start_time": "2020-09-25T20:12:04.589411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Replies</th>\n",
       "      <th>Views</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>daughter soon gone whole life friends never go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>9003</td>\n",
       "      <td>nicest start summer holidays get altercation k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>hmmhmmpost edited michelino pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>4114</td>\n",
       "      <td>hope im posting right place hope one give advi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3179</td>\n",
       "      <td>last week school daughters class one girls dec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Replies  Views                                         text_clean\n",
       "0        2     55  daughter soon gone whole life friends never go...\n",
       "1       23   9003  nicest start summer holidays get altercation k...\n",
       "2        0     13                     hmmhmmpost edited michelino pm\n",
       "3       12   4114  hope im posting right place hope one give advi...\n",
       "4        5   3179  last week school daughters class one girls dec..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nm['text_clean'] = nm['text_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming & Lemmatizing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T20:42:12.438552Z",
     "start_time": "2020-09-25T20:42:08.835864Z"
    }
   },
   "outputs": [],
   "source": [
    "nm['text_tokens'] = nm['text_clean'].apply(lambda x: word_tokenize(x))\n",
    "nm['text_tokens_lemma'] = nm['text_tokens'].apply(lambda x: word_lemmatizer(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**POS Tagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T20:42:38.960574Z",
     "start_time": "2020-09-25T20:42:13.909959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Replies</th>\n",
       "      <th>Views</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_tokens_lemma</th>\n",
       "      <th>text_tokens_pos_tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>daughter soon gone whole life friends never go...</td>\n",
       "      <td>[daughter, soon, gone, whole, life, friends, n...</td>\n",
       "      <td>[daughter, soon, gone, whole, life, friend, ne...</td>\n",
       "      <td>[(daughter, NN), (soon, RB), (gone, VBN), (who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>9003</td>\n",
       "      <td>nicest start summer holidays get altercation k...</td>\n",
       "      <td>[nicest, start, summer, holidays, get, alterca...</td>\n",
       "      <td>[nicest, start, summer, holiday, get, altercat...</td>\n",
       "      <td>[(nicest, JJS), (start, NN), (summer, NN), (ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>hmmhmmpost edited michelino pm</td>\n",
       "      <td>[hmmhmmpost, edited, michelino, pm]</td>\n",
       "      <td>[hmmhmmpost, edited, michelino, pm]</td>\n",
       "      <td>[(hmmhmmpost, NN), (edited, VBD), (michelino, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>4114</td>\n",
       "      <td>hope im posting right place hope one give advi...</td>\n",
       "      <td>[hope, im, posting, right, place, hope, one, g...</td>\n",
       "      <td>[hope, im, posting, right, place, hope, one, g...</td>\n",
       "      <td>[(hope, NN), (im, NN), (posting, VBG), (right,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3179</td>\n",
       "      <td>last week school daughters class one girls dec...</td>\n",
       "      <td>[last, week, school, daughters, class, one, gi...</td>\n",
       "      <td>[last, week, school, daughter, class, one, gir...</td>\n",
       "      <td>[(last, JJ), (week, NN), (school, NN), (daught...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Replies  Views                                         text_clean  \\\n",
       "0        2     55  daughter soon gone whole life friends never go...   \n",
       "1       23   9003  nicest start summer holidays get altercation k...   \n",
       "2        0     13                     hmmhmmpost edited michelino pm   \n",
       "3       12   4114  hope im posting right place hope one give advi...   \n",
       "4        5   3179  last week school daughters class one girls dec...   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  [daughter, soon, gone, whole, life, friends, n...   \n",
       "1  [nicest, start, summer, holidays, get, alterca...   \n",
       "2                [hmmhmmpost, edited, michelino, pm]   \n",
       "3  [hope, im, posting, right, place, hope, one, g...   \n",
       "4  [last, week, school, daughters, class, one, gi...   \n",
       "\n",
       "                                   text_tokens_lemma  \\\n",
       "0  [daughter, soon, gone, whole, life, friend, ne...   \n",
       "1  [nicest, start, summer, holiday, get, altercat...   \n",
       "2                [hmmhmmpost, edited, michelino, pm]   \n",
       "3  [hope, im, posting, right, place, hope, one, g...   \n",
       "4  [last, week, school, daughter, class, one, gir...   \n",
       "\n",
       "                              text_tokens_pos_tagged  \n",
       "0  [(daughter, NN), (soon, RB), (gone, VBN), (who...  \n",
       "1  [(nicest, JJS), (start, NN), (summer, NN), (ho...  \n",
       "2  [(hmmhmmpost, NN), (edited, VBD), (michelino, ...  \n",
       "3  [(hope, NN), (im, NN), (posting, VBG), (right,...  \n",
       "4  [(last, JJ), (week, NN), (school, NN), (daught...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nm['text_tokens_pos_tagged'] = nm['text_tokens'].apply(lambda x: word_pos_tagger(x))\n",
    "nm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chunking** - Extracting meaningfull info from the tagged_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T21:03:36.145957Z",
     "start_time": "2020-09-25T21:03:36.118032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forest fire NP fire\n",
      "la ronge sask canada NP canada\n"
     ]
    }
   ],
   "source": [
    "text = nlp(\"forest fire near la ronge sask canada\")\n",
    "for chunk in text.noun_chunks:\n",
    "    print(chunk.text, chunk.label_, chunk.root.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
